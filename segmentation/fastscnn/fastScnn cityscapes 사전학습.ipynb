{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d5ebff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['.ipynb_checkpoints', 'bisenetv2.py', '__pycache__', 'modules.py', '__init__.py', 'model_registry.py', 'BiSeNet_V2.py', 'fastscnn.py', 'fast_scnn.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 'models' í´ë”ê°€ ìžˆëŠ”ì§€ í™•ì¸\n",
    "models_path = \"/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/models\"\n",
    "print(os.path.exists(models_path))  # Trueë©´ ì¡´ìž¬, Falseë©´ ì—†ìŒ\n",
    "\n",
    "# í´ë” ë‚´ë¶€ íŒŒì¼ í™•ì¸\n",
    "if os.path.exists(models_path):\n",
    "    print(os.listdir(models_path))  # 'fast_scnn.py'ê°€ ìžˆëŠ”ì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d746202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python ê²½ë¡œ ëª©ë¡:\n",
      "/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master\n",
      "/aiffel/storage/package\n",
      "/opt/conda/lib/python39.zip\n",
      "/opt/conda/lib/python3.9\n",
      "/opt/conda/lib/python3.9/lib-dynload\n",
      "\n",
      "/opt/conda/lib/python3.9/site-packages\n",
      "/opt/conda/lib/python3.9/site-packages/IPython/extensions\n",
      "/aiffel/.ipython\n",
      "/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/models\n",
      "/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/utils\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Python ëª¨ë“ˆ ê²½ë¡œì— 'models' í´ë” ì¶”ê°€\n",
    "models_path = \"/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/models\"\n",
    "utils_path = \"/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/utils\"\n",
    "\n",
    "if models_path not in sys.path:\n",
    "    sys.path.append(models_path)  # models í´ë” ì¶”ê°€\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)  # utils í´ë” ì¶”ê°€\n",
    "\n",
    "# sys.path í™•ì¸ (ì œëŒ€ë¡œ ì¶”ê°€ë˜ì—ˆëŠ”ì§€)\n",
    "print(\"Python ê²½ë¡œ ëª©ë¡:\")\n",
    "print(\"\\n\".join(sys.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774aec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "# PyTorch ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# ì´ë¯¸ì§€ ë³€í™˜ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from torchvision import transforms\n",
    "\n",
    "# ë°ì´í„° ë¡œë” ë° ëª¨ë¸, ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from data_loader import get_segmentation_dataset  # ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜\n",
    "from models.fast_scnn import get_fast_scnn  # Fast-SCNN ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from utils.loss import MixSoftmaxCrossEntropyLoss, MixSoftmaxCrossEntropyOHEMLoss  # ì†ì‹¤ í•¨ìˆ˜\n",
    "from utils.lr_scheduler import LRScheduler  # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "from utils.metric import SegmentationMetric  # í‰ê°€ ì§€í‘œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b59c9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë° í•™ìŠµ ê´€ë ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "args = {\n",
    "    \"model\": \"fast_scnn\",  # ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„\n",
    "    \"dataset\": \"citys\",  # í•™ìŠµí•  ë°ì´í„°ì…‹ (ì˜ˆ: Cityscapes)\n",
    "    \"base_size\": 1024,  # ìž…ë ¥ ì´ë¯¸ì§€ ê¸°ë³¸ í¬ê¸°\n",
    "    \"crop_size\": 768,  # í•™ìŠµ ì‹œ ì‚¬ìš©í•  í¬ë¡­ í¬ê¸°\n",
    "    \"train_split\": \"train\",  # í•™ìŠµ ë°ì´í„°ì…‹ì˜ ë¶„í•  ë°©ì‹\n",
    "\n",
    "    # í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "    \"aux\": False,  # ë³´ì¡° ì†ì‹¤ ì‚¬ìš© ì—¬ë¶€\n",
    "    \"aux_weight\": 0.4,  # ë³´ì¡° ì†ì‹¤ ê°€ì¤‘ì¹˜\n",
    "    \"epochs\": 10,  # í•™ìŠµ ì—í­ ìˆ˜\n",
    "    \"start_epoch\": 0,  # í•™ìŠµ ì‹œìž‘ ì—í­\n",
    "    \"batch_size\": 2,  # ë°°ì¹˜ í¬ê¸°\n",
    "    \"lr\": 1e-2,  # í•™ìŠµë¥ \n",
    "    \"momentum\": 0.9,  # ëª¨ë©˜í…€\n",
    "    \"weight_decay\": 1e-4,  # ê°€ì¤‘ì¹˜ ê°ì‡  (L2 ì •ê·œí™”)\n",
    "\n",
    "    # ì²´í¬í¬ì¸íŠ¸ ì €ìž¥ ìœ„ì¹˜\n",
    "    \"resume\": True,  # ê¸°ì¡´ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)\n",
    "    \"save_folder\": \"./weights\",  # ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ìž¥ ê²½ë¡œ\n",
    "\n",
    "    # í‰ê°€ ë° ê²€ì¦ ì„¤ì •\n",
    "    \"eval\": True,  # í‰ê°€ ëª¨ë“œ ì—¬ë¶€\n",
    "    \"no_val\": False,  # ê²€ì¦ ìƒëžµ ì—¬ë¶€\n",
    "}\n",
    "\n",
    "# GPU ì‚¬ìš© ì—¬ë¶€ ì„¤ì •\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True  # GPU ì—°ì‚° ìµœì í™”\n",
    "args[\"device\"] = device  # í•™ìŠµì— ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ì €ìž¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f53ec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ 'train' í´ë” ì¡´ìž¬ ì—¬ë¶€: True\n",
      "ðŸ“‚ 'train' í´ë” ë‚´ë¶€ íŒŒì¼: ['zurich', 'monchengladbach', 'strasbourg', 'weimar', 'erfurt', 'stuttgart', 'tubingen', 'ulm', 'cologne', 'krefeld', 'hamburg', 'aachen', 'jena', 'bremen', 'bochum', 'dusseldorf', 'darmstadt', 'hanover']\n"
     ]
    }
   ],
   "source": [
    "train_img_path = \"/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/datasets/citys/leftImg8bit/train\"\n",
    "\n",
    "# train í´ë” ì¡´ìž¬ ì—¬ë¶€ í™•ì¸\n",
    "print(\"ðŸ“‚ 'train' í´ë” ì¡´ìž¬ ì—¬ë¶€:\", os.path.exists(train_img_path))\n",
    "\n",
    "# train í´ë” ë‚´ë¶€ íŒŒì¼ í™•ì¸\n",
    "if os.path.exists(train_img_path):\n",
    "    print(\"ðŸ“‚ 'train' í´ë” ë‚´ë¶€ íŒŒì¼:\", os.listdir(train_img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc2dae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Found gtFine folder at: /aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/datasets/citys/gtFine\n"
     ]
    }
   ],
   "source": [
    "dataset_root = \"/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/datasets\"\n",
    "\n",
    "# ðŸ” `gtFine` í´ë”ê°€ ì–´ë”” ìžˆëŠ”ì§€ í™•ì¸\n",
    "for root, dirs, files in os.walk(dataset_root):\n",
    "    if \"gtFine\" in dirs:\n",
    "        print(f\"ðŸ“‚ Found gtFine folder at: {os.path.join(root, 'gtFine')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "188a67bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2975 images in /aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/datasets/citys/leftImg8bit/train\n",
      "Found 500 images in /aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/datasets/citys/leftImg8bit/val\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FastSCNN(\n",
       "  (learning_to_downsample): LearningToDownsample(\n",
       "    (conv): _ConvBNReLU(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dsconv1): _DSConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dsconv2): _DSConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (global_feature_extractor): GlobalFeatureExtractor(\n",
       "    (bottleneck1): Sequential(\n",
       "      (0): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bottleneck2): Sequential(\n",
       "      (0): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bottleneck3): Sequential(\n",
       "      (0): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ppm): PyramidPooling(\n",
       "      (conv1): _ConvBNReLU(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2): _ConvBNReLU(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv3): _ConvBNReLU(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv4): _ConvBNReLU(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (out): _ConvBNReLU(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feature_fusion): FeatureFusionModule(\n",
       "    (dwconv): _DWConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_lower_res): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_higher_res): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Classifer(\n",
       "    (dsconv1): _DSConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dsconv2): _DSConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë³€í™˜ ì„¤ì •\n",
    "input_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # ì´ë¯¸ì§€ë¥¼ Tensorë¡œ ë³€í™˜\n",
    "    transforms.Normalize([.485, .456, .406], [.229, .224, .225]),  # ì´ë¯¸ì§€ ì •ê·œí™”\n",
    "])\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¡œë“œ (í•™ìŠµ ë° ê²€ì¦)\n",
    "data_kwargs = {\"transform\": input_transform, \"base_size\": args[\"base_size\"], \"crop_size\": args[\"crop_size\"]}\n",
    "train_dataset = get_segmentation_dataset(args[\"dataset\"], split=args[\"train_split\"], mode=\"train\", **data_kwargs)\n",
    "val_dataset = get_segmentation_dataset(args[\"dataset\"], split=\"val\", mode=\"val\", **data_kwargs)\n",
    "\n",
    "# DataLoader ìƒì„± (ë°ì´í„° ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¡œë”©)\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=args[\"batch_size\"], shuffle=True, drop_last=True)\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Fast-SCNN ëª¨ë¸ ìƒì„±\n",
    "model = get_fast_scnn(dataset=args[\"dataset\"], aux=args[\"aux\"])\n",
    "\n",
    "# GPU ë³‘ë ¬ ì²˜ë¦¬ ì§€ì› (ë©€í‹° GPU ì‚¬ìš© ê°€ëŠ¥)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0, 1, 2])\n",
    "\n",
    "# ëª¨ë¸ì„ GPU ë˜ëŠ” CPUë¡œ ì´ë™\n",
    "model.to(args[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8379a3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastSCNN(\n",
      "  (learning_to_downsample): LearningToDownsample(\n",
      "    (conv): _ConvBNReLU(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (dsconv1): _DSConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (dsconv2): _DSConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (global_feature_extractor): GlobalFeatureExtractor(\n",
      "    (bottleneck1): Sequential(\n",
      "      (0): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bottleneck2): Sequential(\n",
      "      (0): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bottleneck3): Sequential(\n",
      "      (0): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ppm): PyramidPooling(\n",
      "      (conv1): _ConvBNReLU(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv2): _ConvBNReLU(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv3): _ConvBNReLU(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv4): _ConvBNReLU(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (out): _ConvBNReLU(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feature_fusion): FeatureFusionModule(\n",
      "    (dwconv): _DWConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv_lower_res): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv_higher_res): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Classifer(\n",
      "    (dsconv1): _DSConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (dsconv2): _DSConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv): Sequential(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)  # ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì„ ì–¸ë˜ì—ˆëŠ”ì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4d68ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ class balance\n"
     ]
    }
   ],
   "source": [
    "# ì†ì‹¤ í•¨ìˆ˜ ì„¤ì • (OHEM Loss ì‚¬ìš©)\n",
    "criterion = MixSoftmaxCrossEntropyOHEMLoss(aux=args[\"aux\"], aux_weight=args[\"aux_weight\"], ignore_index=-1).to(args[\"device\"])\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì € (SGD ì‚¬ìš©)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=args[\"lr\"], momentum=args[\"momentum\"], weight_decay=args[\"weight_decay\"])\n",
    "\n",
    "# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • (poly decay ì‚¬ìš©)\n",
    "lr_scheduler = LRScheduler(mode=\"poly\", base_lr=args[\"lr\"], nepochs=args[\"epochs\"],\n",
    "                           iters_per_epoch=len(train_loader), power=0.9)\n",
    "\n",
    "# í‰ê°€ ì§€í‘œ (mIoU ë“±)\n",
    "metric = SegmentationMetric(train_dataset.num_class)\n",
    "\n",
    "# ìµœê³  ì„±ëŠ¥ ì €ìž¥ì„ ìœ„í•œ ë³€ìˆ˜\n",
    "best_pred = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c4e5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global best_pred  # ìµœê³  ì„±ëŠ¥ ë¹„êµë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ ì‚¬ìš©\n",
    "    cur_iters = 0  # í˜„ìž¬ ë°˜ë³µ íšŸìˆ˜\n",
    "    start_time = time.time()  # í•™ìŠµ ì‹œìž‘ ì‹œê°„\n",
    "\n",
    "    # ê° ì—í­ë§ˆë‹¤ í•™ìŠµ ìˆ˜í–‰\n",
    "    for epoch in range(args[\"start_epoch\"], args[\"epochs\"]):\n",
    "        model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •\n",
    "\n",
    "        for i, (images, targets) in enumerate(train_loader):\n",
    "            cur_lr = lr_scheduler(cur_iters)  # í˜„ìž¬ í•™ìŠµë¥  ì„¤ì •\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = cur_lr  # ì˜µí‹°ë§ˆì´ì €ì— í•™ìŠµë¥  ì ìš©\n",
    "\n",
    "            # ë°ì´í„°ë¥¼ GPU/CPUë¡œ ì´ë™\n",
    "            images, targets = images.to(args[\"device\"]), targets.to(args[\"device\"])\n",
    "\n",
    "            # ëª¨ë¸ ì˜ˆì¸¡ ë° ì†ì‹¤ ê³„ì‚°\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # ì—­ì „íŒŒ ë° ìµœì í™” ìˆ˜í–‰\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            cur_iters += 1  # ë°˜ë³µ íšŸìˆ˜ ì¦ê°€\n",
    "            if cur_iters % 10 == 0:  # 10íšŒë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥\n",
    "                print(f\"Epoch [{epoch}/{args['epochs']}], Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # ê²€ì¦ ìˆ˜í–‰ ë° ì²´í¬í¬ì¸íŠ¸ ì €ìž¥\n",
    "        if not args[\"no_val\"]:\n",
    "            validation(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ef92eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    global best_pred  # ìµœê³  ì„±ëŠ¥ ë¹„êµë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ ì‚¬ìš©\n",
    "    model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ë³€ê²½\n",
    "    metric.reset()  # í‰ê°€ ì§€í‘œ ì´ˆê¸°í™”\n",
    "\n",
    "    for i, (image, target) in enumerate(val_loader):\n",
    "        image = image.to(args[\"device\"])  # ì´ë¯¸ì§€ë¥¼ GPU/CPUë¡œ ì´ë™\n",
    "\n",
    "        with torch.no_grad():  # ê·¸ëž˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”\n",
    "            outputs = model(image)\n",
    "\n",
    "        pred = torch.argmax(outputs[0], 1).cpu().data.numpy()  # ì˜ˆì¸¡ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "        metric.update(pred, target.numpy())  # í‰ê°€ ì§€í‘œ ì—…ë°ì´íŠ¸\n",
    "\n",
    "    pixAcc, mIoU = metric.get()  # í”½ì…€ ì •í™•ë„ ë° mIoU ê³„ì‚°\n",
    "    print(f\"Epoch {epoch}, Validation PixAcc: {pixAcc:.3f}, mIoU: {mIoU:.3f}\")\n",
    "\n",
    "    new_pred = (pixAcc + mIoU) / 2  # ì„±ëŠ¥ í‰ê°€\n",
    "    if new_pred > best_pred:\n",
    "        best_pred = new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d4a1e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10], Step [9/1487], Loss: 1.6984\n",
      "Epoch [0/10], Step [19/1487], Loss: 2.1239\n",
      "Epoch [0/10], Step [29/1487], Loss: 2.0295\n",
      "Epoch [0/10], Step [39/1487], Loss: 2.1423\n",
      "Epoch [0/10], Step [49/1487], Loss: 1.4570\n",
      "Epoch [0/10], Step [59/1487], Loss: 1.7141\n",
      "Epoch [0/10], Step [69/1487], Loss: 1.4954\n",
      "Epoch [0/10], Step [79/1487], Loss: 1.5687\n",
      "Epoch [0/10], Step [89/1487], Loss: 2.0716\n",
      "Epoch [0/10], Step [99/1487], Loss: 1.7081\n",
      "Epoch [0/10], Step [109/1487], Loss: 2.5222\n",
      "Epoch [0/10], Step [119/1487], Loss: 1.4102\n",
      "Epoch [0/10], Step [129/1487], Loss: 1.8364\n",
      "Epoch [0/10], Step [139/1487], Loss: 1.6245\n",
      "Epoch [0/10], Step [149/1487], Loss: 2.1214\n",
      "Epoch [0/10], Step [159/1487], Loss: 1.2951\n",
      "Epoch [0/10], Step [169/1487], Loss: 1.9539\n",
      "Epoch [0/10], Step [179/1487], Loss: 1.6137\n",
      "Epoch [0/10], Step [189/1487], Loss: 1.8407\n",
      "Epoch [0/10], Step [199/1487], Loss: 2.1681\n",
      "Epoch [0/10], Step [209/1487], Loss: 1.5661\n",
      "Epoch [0/10], Step [219/1487], Loss: 1.3354\n",
      "Epoch [0/10], Step [229/1487], Loss: 1.0910\n",
      "Epoch [0/10], Step [239/1487], Loss: 1.8617\n",
      "Epoch [0/10], Step [249/1487], Loss: 1.7552\n",
      "Epoch [0/10], Step [259/1487], Loss: 1.3287\n",
      "Epoch [0/10], Step [269/1487], Loss: 0.8835\n",
      "Epoch [0/10], Step [279/1487], Loss: 2.0748\n",
      "Epoch [0/10], Step [289/1487], Loss: 1.8686\n",
      "Epoch [0/10], Step [299/1487], Loss: 1.7459\n",
      "Epoch [0/10], Step [309/1487], Loss: 2.0701\n",
      "Epoch [0/10], Step [319/1487], Loss: 2.0815\n",
      "Epoch [0/10], Step [329/1487], Loss: 1.6378\n",
      "Epoch [0/10], Step [339/1487], Loss: 1.0346\n",
      "Epoch [0/10], Step [349/1487], Loss: 2.1617\n",
      "Epoch [0/10], Step [359/1487], Loss: 1.5996\n",
      "Epoch [0/10], Step [369/1487], Loss: 1.3395\n",
      "Epoch [0/10], Step [379/1487], Loss: 1.3044\n",
      "Epoch [0/10], Step [389/1487], Loss: 1.9684\n",
      "Epoch [0/10], Step [399/1487], Loss: 1.8221\n",
      "Epoch [0/10], Step [409/1487], Loss: 1.2148\n",
      "Epoch [0/10], Step [419/1487], Loss: 2.2878\n",
      "Epoch [0/10], Step [429/1487], Loss: 1.0897\n",
      "Epoch [0/10], Step [439/1487], Loss: 1.8783\n",
      "Epoch [0/10], Step [449/1487], Loss: 2.1254\n",
      "Epoch [0/10], Step [459/1487], Loss: 1.9082\n",
      "Epoch [0/10], Step [469/1487], Loss: 1.5183\n",
      "Epoch [0/10], Step [479/1487], Loss: 1.1856\n",
      "Epoch [0/10], Step [489/1487], Loss: 1.1039\n",
      "Epoch [0/10], Step [499/1487], Loss: 1.3850\n",
      "Epoch [0/10], Step [509/1487], Loss: 1.7692\n",
      "Epoch [0/10], Step [519/1487], Loss: 1.1901\n",
      "Epoch [0/10], Step [529/1487], Loss: 1.2255\n",
      "Epoch [0/10], Step [539/1487], Loss: 1.7085\n",
      "Epoch [0/10], Step [549/1487], Loss: 1.4465\n",
      "Epoch [0/10], Step [559/1487], Loss: 1.5739\n",
      "Epoch [0/10], Step [569/1487], Loss: 1.4968\n",
      "Epoch [0/10], Step [579/1487], Loss: 1.1759\n",
      "Epoch [0/10], Step [589/1487], Loss: 1.9207\n",
      "Epoch [0/10], Step [599/1487], Loss: 1.4850\n",
      "Epoch [0/10], Step [609/1487], Loss: 1.5424\n",
      "Epoch [0/10], Step [619/1487], Loss: 2.3259\n",
      "Epoch [0/10], Step [629/1487], Loss: 0.9589\n",
      "Epoch [0/10], Step [639/1487], Loss: 2.7854\n",
      "Epoch [0/10], Step [649/1487], Loss: 1.2647\n",
      "Epoch [0/10], Step [659/1487], Loss: 2.0985\n",
      "Epoch [0/10], Step [669/1487], Loss: 2.8104\n",
      "Epoch [0/10], Step [679/1487], Loss: 1.3176\n",
      "Epoch [0/10], Step [689/1487], Loss: 1.0936\n",
      "Epoch [0/10], Step [699/1487], Loss: 1.9969\n",
      "Epoch [0/10], Step [709/1487], Loss: 2.5464\n",
      "Epoch [0/10], Step [719/1487], Loss: 1.5387\n",
      "Epoch [0/10], Step [729/1487], Loss: 1.9397\n",
      "Epoch [0/10], Step [739/1487], Loss: 1.0302\n",
      "Epoch [0/10], Step [749/1487], Loss: 1.5023\n",
      "Epoch [0/10], Step [759/1487], Loss: 1.5055\n",
      "Epoch [0/10], Step [769/1487], Loss: 1.1510\n",
      "Epoch [0/10], Step [779/1487], Loss: 1.5884\n",
      "Epoch [0/10], Step [789/1487], Loss: 1.5008\n",
      "Epoch [0/10], Step [799/1487], Loss: 2.4832\n",
      "Epoch [0/10], Step [809/1487], Loss: 1.0713\n",
      "Epoch [0/10], Step [819/1487], Loss: 1.0631\n",
      "Epoch [0/10], Step [829/1487], Loss: 2.2233\n",
      "Epoch [0/10], Step [839/1487], Loss: 1.0809\n",
      "Epoch [0/10], Step [849/1487], Loss: 1.2609\n",
      "Epoch [0/10], Step [859/1487], Loss: 2.6322\n",
      "Epoch [0/10], Step [869/1487], Loss: 1.8297\n",
      "Epoch [0/10], Step [879/1487], Loss: 1.4062\n",
      "Epoch [0/10], Step [889/1487], Loss: 1.3260\n",
      "Epoch [0/10], Step [899/1487], Loss: 1.6917\n",
      "Epoch [0/10], Step [909/1487], Loss: 1.4675\n",
      "Epoch [0/10], Step [919/1487], Loss: 2.1544\n",
      "Epoch [0/10], Step [929/1487], Loss: 1.0185\n",
      "Epoch [0/10], Step [939/1487], Loss: 1.2007\n",
      "Epoch [0/10], Step [949/1487], Loss: 2.0397\n",
      "Epoch [0/10], Step [959/1487], Loss: 1.0580\n",
      "Epoch [0/10], Step [969/1487], Loss: 1.2528\n",
      "Epoch [0/10], Step [979/1487], Loss: 1.3412\n",
      "Epoch [0/10], Step [989/1487], Loss: 1.9848\n",
      "Epoch [0/10], Step [999/1487], Loss: 1.5030\n",
      "Epoch [0/10], Step [1009/1487], Loss: 4.4350\n",
      "Epoch [0/10], Step [1019/1487], Loss: 1.3963\n",
      "Epoch [0/10], Step [1029/1487], Loss: 1.1061\n",
      "Epoch [0/10], Step [1039/1487], Loss: 1.5683\n",
      "Epoch [0/10], Step [1049/1487], Loss: 1.7266\n",
      "Epoch [0/10], Step [1059/1487], Loss: 1.3342\n",
      "Epoch [0/10], Step [1069/1487], Loss: 1.6502\n",
      "Epoch [0/10], Step [1079/1487], Loss: 1.4327\n",
      "Epoch [0/10], Step [1089/1487], Loss: 1.7473\n",
      "Epoch [0/10], Step [1099/1487], Loss: 1.5208\n",
      "Epoch [0/10], Step [1109/1487], Loss: 1.3866\n",
      "Epoch [0/10], Step [1119/1487], Loss: 1.0815\n",
      "Epoch [0/10], Step [1129/1487], Loss: 1.2476\n",
      "Epoch [0/10], Step [1139/1487], Loss: 1.7420\n",
      "Epoch [0/10], Step [1149/1487], Loss: 1.3661\n",
      "Epoch [0/10], Step [1159/1487], Loss: 1.2156\n",
      "Epoch [0/10], Step [1169/1487], Loss: 1.3085\n",
      "Epoch [0/10], Step [1179/1487], Loss: 1.0748\n",
      "Epoch [0/10], Step [1189/1487], Loss: 1.4073\n",
      "Epoch [0/10], Step [1199/1487], Loss: 1.2499\n",
      "Epoch [0/10], Step [1209/1487], Loss: 1.2046\n",
      "Epoch [0/10], Step [1219/1487], Loss: 2.0282\n",
      "Epoch [0/10], Step [1229/1487], Loss: 1.8089\n",
      "Epoch [0/10], Step [1239/1487], Loss: 1.1074\n",
      "Epoch [0/10], Step [1249/1487], Loss: 1.2026\n",
      "Epoch [0/10], Step [1259/1487], Loss: 1.4315\n",
      "Epoch [0/10], Step [1269/1487], Loss: 1.5152\n",
      "Epoch [0/10], Step [1279/1487], Loss: 1.2723\n",
      "Epoch [0/10], Step [1289/1487], Loss: 1.3169\n",
      "Epoch [0/10], Step [1299/1487], Loss: 1.4018\n",
      "Epoch [0/10], Step [1309/1487], Loss: 1.0477\n",
      "Epoch [0/10], Step [1319/1487], Loss: 2.2070\n",
      "Epoch [0/10], Step [1329/1487], Loss: 1.4879\n",
      "Epoch [0/10], Step [1339/1487], Loss: 0.9701\n",
      "Epoch [0/10], Step [1349/1487], Loss: 1.6721\n",
      "Epoch [0/10], Step [1359/1487], Loss: 1.2448\n",
      "Epoch [0/10], Step [1369/1487], Loss: 1.4519\n",
      "Epoch [0/10], Step [1379/1487], Loss: 1.0859\n",
      "Epoch [0/10], Step [1389/1487], Loss: 1.4396\n",
      "Epoch [0/10], Step [1399/1487], Loss: 3.3655\n",
      "Epoch [0/10], Step [1409/1487], Loss: 2.6691\n",
      "Epoch [0/10], Step [1419/1487], Loss: 1.5767\n",
      "Epoch [0/10], Step [1429/1487], Loss: 1.3931\n",
      "Epoch [0/10], Step [1439/1487], Loss: 1.7842\n",
      "Epoch [0/10], Step [1449/1487], Loss: 1.2066\n",
      "Epoch [0/10], Step [1459/1487], Loss: 1.2053\n",
      "Epoch [0/10], Step [1469/1487], Loss: 1.4126\n",
      "Epoch [0/10], Step [1479/1487], Loss: 1.0258\n",
      "Epoch 0, Validation PixAcc: 0.817, mIoU: 0.197\n",
      "Epoch [1/10], Step [2/1487], Loss: 1.5527\n",
      "Epoch [1/10], Step [12/1487], Loss: 0.8897\n",
      "Epoch [1/10], Step [22/1487], Loss: 2.0318\n",
      "Epoch [1/10], Step [32/1487], Loss: 1.0497\n",
      "Epoch [1/10], Step [42/1487], Loss: 1.7643\n",
      "Epoch [1/10], Step [52/1487], Loss: 1.7934\n",
      "Epoch [1/10], Step [62/1487], Loss: 1.0345\n",
      "Epoch [1/10], Step [72/1487], Loss: 1.5978\n",
      "Epoch [1/10], Step [82/1487], Loss: 1.2543\n",
      "Epoch [1/10], Step [92/1487], Loss: 1.7044\n",
      "Epoch [1/10], Step [102/1487], Loss: 1.6678\n",
      "Epoch [1/10], Step [112/1487], Loss: 2.1271\n",
      "Epoch [1/10], Step [122/1487], Loss: 1.7572\n",
      "Epoch [1/10], Step [132/1487], Loss: 1.0134\n",
      "Epoch [1/10], Step [142/1487], Loss: 1.1593\n",
      "Epoch [1/10], Step [152/1487], Loss: 1.3203\n",
      "Epoch [1/10], Step [162/1487], Loss: 1.0061\n",
      "Epoch [1/10], Step [172/1487], Loss: 1.2956\n",
      "Epoch [1/10], Step [182/1487], Loss: 2.2166\n",
      "Epoch [1/10], Step [192/1487], Loss: 0.8275\n",
      "Epoch [1/10], Step [202/1487], Loss: 1.1134\n",
      "Epoch [1/10], Step [212/1487], Loss: 1.4325\n",
      "Epoch [1/10], Step [222/1487], Loss: 1.6833\n",
      "Epoch [1/10], Step [232/1487], Loss: 1.1990\n",
      "Epoch [1/10], Step [242/1487], Loss: 1.3488\n",
      "Epoch [1/10], Step [252/1487], Loss: 1.2242\n",
      "Epoch [1/10], Step [262/1487], Loss: 2.1031\n",
      "Epoch [1/10], Step [272/1487], Loss: 1.7372\n",
      "Epoch [1/10], Step [282/1487], Loss: 1.1702\n",
      "Epoch [1/10], Step [292/1487], Loss: 2.0115\n",
      "Epoch [1/10], Step [302/1487], Loss: 1.0719\n",
      "Epoch [1/10], Step [312/1487], Loss: 1.0588\n",
      "Epoch [1/10], Step [322/1487], Loss: 1.2002\n",
      "Epoch [1/10], Step [332/1487], Loss: 2.4756\n",
      "Epoch [1/10], Step [342/1487], Loss: 0.9701\n",
      "Epoch [1/10], Step [352/1487], Loss: 2.0005\n",
      "Epoch [1/10], Step [362/1487], Loss: 2.1460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [372/1487], Loss: 1.8904\n",
      "Epoch [1/10], Step [382/1487], Loss: 1.4418\n",
      "Epoch [1/10], Step [392/1487], Loss: 1.1142\n",
      "Epoch [1/10], Step [402/1487], Loss: 1.1185\n",
      "Epoch [1/10], Step [412/1487], Loss: 1.4657\n",
      "Epoch [1/10], Step [422/1487], Loss: 1.0007\n",
      "Epoch [1/10], Step [432/1487], Loss: 1.7595\n",
      "Epoch [1/10], Step [442/1487], Loss: 1.4036\n",
      "Epoch [1/10], Step [452/1487], Loss: 1.0686\n",
      "Epoch [1/10], Step [462/1487], Loss: 1.3525\n",
      "Epoch [1/10], Step [472/1487], Loss: 1.3537\n",
      "Epoch [1/10], Step [482/1487], Loss: 1.0825\n",
      "Epoch [1/10], Step [492/1487], Loss: 1.4741\n",
      "Epoch [1/10], Step [502/1487], Loss: 1.6350\n",
      "Epoch [1/10], Step [512/1487], Loss: 1.7159\n",
      "Epoch [1/10], Step [522/1487], Loss: 1.5469\n",
      "Epoch [1/10], Step [532/1487], Loss: 1.0567\n",
      "Epoch [1/10], Step [542/1487], Loss: 1.5321\n",
      "Epoch [1/10], Step [552/1487], Loss: 1.1166\n",
      "Epoch [1/10], Step [562/1487], Loss: 3.7772\n",
      "Epoch [1/10], Step [572/1487], Loss: 1.4862\n",
      "Epoch [1/10], Step [582/1487], Loss: 1.6080\n",
      "Epoch [1/10], Step [592/1487], Loss: 1.3586\n",
      "Epoch [1/10], Step [602/1487], Loss: 1.5337\n",
      "Epoch [1/10], Step [612/1487], Loss: 1.5995\n",
      "Epoch [1/10], Step [622/1487], Loss: 1.2151\n",
      "Epoch [1/10], Step [632/1487], Loss: 1.9095\n",
      "Epoch [1/10], Step [642/1487], Loss: 1.9407\n",
      "Epoch [1/10], Step [652/1487], Loss: 1.0465\n",
      "Epoch [1/10], Step [662/1487], Loss: 1.5238\n",
      "Epoch [1/10], Step [672/1487], Loss: 1.3173\n",
      "Epoch [1/10], Step [682/1487], Loss: 2.3505\n",
      "Epoch [1/10], Step [692/1487], Loss: 0.9730\n",
      "Epoch [1/10], Step [702/1487], Loss: 0.8187\n",
      "Epoch [1/10], Step [712/1487], Loss: 1.4580\n",
      "Epoch [1/10], Step [722/1487], Loss: 1.2289\n",
      "Epoch [1/10], Step [732/1487], Loss: 1.4908\n",
      "Epoch [1/10], Step [742/1487], Loss: 5.0667\n",
      "Epoch [1/10], Step [752/1487], Loss: 1.2834\n",
      "Epoch [1/10], Step [762/1487], Loss: 1.1705\n",
      "Epoch [1/10], Step [772/1487], Loss: 1.6588\n",
      "Epoch [1/10], Step [782/1487], Loss: 1.6832\n",
      "Epoch [1/10], Step [792/1487], Loss: 1.6049\n",
      "Epoch [1/10], Step [802/1487], Loss: 2.1417\n",
      "Epoch [1/10], Step [812/1487], Loss: 1.1839\n",
      "Epoch [1/10], Step [822/1487], Loss: 1.0866\n",
      "Epoch [1/10], Step [832/1487], Loss: 1.2285\n",
      "Epoch [1/10], Step [842/1487], Loss: 1.9098\n",
      "Epoch [1/10], Step [852/1487], Loss: 1.2743\n",
      "Epoch [1/10], Step [862/1487], Loss: 1.5863\n",
      "Epoch [1/10], Step [872/1487], Loss: 1.6600\n",
      "Epoch [1/10], Step [882/1487], Loss: 1.0863\n",
      "Epoch [1/10], Step [892/1487], Loss: 3.9118\n",
      "Epoch [1/10], Step [902/1487], Loss: 1.9892\n",
      "Epoch [1/10], Step [912/1487], Loss: 1.2061\n",
      "Epoch [1/10], Step [922/1487], Loss: 1.1396\n",
      "Epoch [1/10], Step [932/1487], Loss: 2.1957\n",
      "Epoch [1/10], Step [942/1487], Loss: 1.4038\n",
      "Epoch [1/10], Step [952/1487], Loss: 1.4847\n",
      "Epoch [1/10], Step [962/1487], Loss: 1.3469\n",
      "Epoch [1/10], Step [972/1487], Loss: 1.4811\n",
      "Epoch [1/10], Step [982/1487], Loss: 1.2400\n",
      "Epoch [1/10], Step [992/1487], Loss: 1.5225\n",
      "Epoch [1/10], Step [1002/1487], Loss: 1.1559\n",
      "Epoch [1/10], Step [1012/1487], Loss: 1.3687\n",
      "Epoch [1/10], Step [1022/1487], Loss: 1.0919\n",
      "Epoch [1/10], Step [1032/1487], Loss: 1.1929\n",
      "Epoch [1/10], Step [1042/1487], Loss: 0.9303\n",
      "Epoch [1/10], Step [1052/1487], Loss: 1.5033\n",
      "Epoch [1/10], Step [1062/1487], Loss: 2.8932\n",
      "Epoch [1/10], Step [1072/1487], Loss: 1.7936\n",
      "Epoch [1/10], Step [1082/1487], Loss: 1.3767\n",
      "Epoch [1/10], Step [1092/1487], Loss: 1.1362\n",
      "Epoch [1/10], Step [1102/1487], Loss: 2.0278\n",
      "Epoch [1/10], Step [1112/1487], Loss: 1.2497\n",
      "Epoch [1/10], Step [1122/1487], Loss: 1.9330\n",
      "Epoch [1/10], Step [1132/1487], Loss: 1.0721\n",
      "Epoch [1/10], Step [1142/1487], Loss: 1.1959\n",
      "Epoch [1/10], Step [1152/1487], Loss: 1.4769\n",
      "Epoch [1/10], Step [1162/1487], Loss: 1.6629\n",
      "Epoch [1/10], Step [1172/1487], Loss: 1.3840\n",
      "Epoch [1/10], Step [1182/1487], Loss: 0.9324\n",
      "Epoch [1/10], Step [1192/1487], Loss: 1.1198\n",
      "Epoch [1/10], Step [1202/1487], Loss: 1.5438\n",
      "Epoch [1/10], Step [1212/1487], Loss: 1.9913\n",
      "Epoch [1/10], Step [1222/1487], Loss: 1.1239\n",
      "Epoch [1/10], Step [1232/1487], Loss: 1.1197\n",
      "Epoch [1/10], Step [1242/1487], Loss: 1.8706\n",
      "Epoch [1/10], Step [1252/1487], Loss: 0.9547\n",
      "Epoch [1/10], Step [1262/1487], Loss: 1.1446\n",
      "Epoch [1/10], Step [1272/1487], Loss: 1.0588\n",
      "Epoch [1/10], Step [1282/1487], Loss: 1.1384\n",
      "Epoch [1/10], Step [1292/1487], Loss: 1.5051\n",
      "Epoch [1/10], Step [1302/1487], Loss: 1.4434\n",
      "Epoch [1/10], Step [1312/1487], Loss: 1.4146\n",
      "Epoch [1/10], Step [1322/1487], Loss: 1.1435\n",
      "Epoch [1/10], Step [1332/1487], Loss: 1.7276\n",
      "Epoch [1/10], Step [1342/1487], Loss: 1.9016\n",
      "Epoch [1/10], Step [1352/1487], Loss: 1.2302\n",
      "Epoch [1/10], Step [1362/1487], Loss: 3.4463\n",
      "Epoch [1/10], Step [1372/1487], Loss: 1.5998\n",
      "Epoch [1/10], Step [1382/1487], Loss: 2.5807\n",
      "Epoch [1/10], Step [1392/1487], Loss: 0.9958\n",
      "Epoch [1/10], Step [1402/1487], Loss: 1.5799\n",
      "Epoch [1/10], Step [1412/1487], Loss: 1.3317\n",
      "Epoch [1/10], Step [1422/1487], Loss: 1.1983\n",
      "Epoch [1/10], Step [1432/1487], Loss: 1.3108\n",
      "Epoch [1/10], Step [1442/1487], Loss: 2.3813\n",
      "Epoch [1/10], Step [1452/1487], Loss: 1.2907\n",
      "Epoch [1/10], Step [1462/1487], Loss: 1.1928\n",
      "Epoch [1/10], Step [1472/1487], Loss: 0.8134\n",
      "Epoch [1/10], Step [1482/1487], Loss: 1.1354\n",
      "Epoch 1, Validation PixAcc: 0.837, mIoU: 0.220\n",
      "Epoch [2/10], Step [5/1487], Loss: 1.7048\n",
      "Epoch [2/10], Step [15/1487], Loss: 1.8692\n",
      "Epoch [2/10], Step [25/1487], Loss: 1.6231\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_599/4055063839.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# í•™ìŠµ ì‹œìž‘\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_599/3182864978.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# ëª¨ë¸ ì˜ˆì¸¡ ë° ì†ì‹¤ ê³„ì‚°\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# ì—­ì „íŒŒ ë° ìµœì í™” ìˆ˜í–‰\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/utils/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aux_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMixSoftmaxCrossEntropyOHEMLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/utils/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, predict, target, weight)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_kept\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0mthreshold_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_kept\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthreshold_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()  # í•™ìŠµ ì‹œìž‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986b56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
