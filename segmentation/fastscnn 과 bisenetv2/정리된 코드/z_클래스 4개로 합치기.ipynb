{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff584fa-f8d6-48fc-b188-173b33117639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python ê²½ë¡œ ëª©ë¡:\n",
      "/home/segmentsafestep/miniconda3/envs/jupyter-env/lib/python39.zip\n",
      "/home/segmentsafestep/miniconda3/envs/jupyter-env/lib/python3.9\n",
      "/home/segmentsafestep/miniconda3/envs/jupyter-env/lib/python3.9/lib-dynload\n",
      "\n",
      "/home/segmentsafestep/miniconda3/envs/jupyter-env/lib/python3.9/site-packages\n",
      "/home/segmentsafestep/miniconda3/envs/jupyter-env/lib/python3.9/site-packages/IPython/extensions\n",
      "/home/segmentsafestep/.ipython\n",
      "/home/segmentsafestep/Fast-SCNN-pytorch-master/models\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# PyTorch ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# ì´ë¯¸ì§€ ë³€í™˜ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from torchvision import transforms\n",
    "\n",
    "# ë°ì´í„° ë¡œë” ë° ëª¨ë¸, ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from data_loader import get_segmentation_dataset  # ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜\n",
    "from utils.loss import MixSoftmaxCrossEntropyLoss, MixSoftmaxCrossEntropyOHEMLoss  # ì†ì‹¤ í•¨ìˆ˜\n",
    "from utils.lr_scheduler import LRScheduler  # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "from utils.metric import SegmentationMetric  # í‰ê°€ ì§€í‘œ\n",
    "\n",
    "from modules import conv3x3, conv1x1, DWConvBNAct, PWConvBNAct, ConvBNAct, Activation, SegHead\n",
    "from model_registry import register_model, aux_models\n",
    "\n",
    "# Python ëª¨ë“ˆ ê²½ë¡œì— 'models' í´ë” ì¶”ê°€\n",
    "models_path = \"/home/segmentsafestep/Fast-SCNN-pytorch-master/models\"\n",
    "\n",
    "if models_path not in sys.path:\n",
    "    sys.path.append(models_path)  # models í´ë” ì¶”ê°€\n",
    "    \n",
    "# sys.path í™•ì¸ (ì œëŒ€ë¡œ ì¶”ê°€ë˜ì—ˆëŠ”ì§€)\n",
    "print(\"Python ê²½ë¡œ ëª©ë¡:\")\n",
    "print(\"\\n\".join(sys.path))\n",
    "\n",
    "train_img_path = \"/home/segmentsafestep/Fast-SCNN-pytorch-master/datasets/indobohaeng/leftImg8bit/train\"\n",
    "dataset_root = \"/home/segmentsafestep/Fast-SCNN-pytorch-master/datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da5618c-af2b-4e2b-bc9d-9fe40cfe3943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ë³€í™˜ ì‹œì‘: /home/segmentsafestep/Fast-SCNN-pytorch-master/datasets/indobohaeng/gtFine_5class/Val/alley\n",
      "ì´ 2306ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ğŸ”¤ ì†Œë¬¸ì ì´ë¯¸ì§€: 2306ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ¨ ì»¬ëŸ¬ + í‘ë°± ë³€í™˜ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2306/2306 [59:24<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë³€í™˜ ì™„ë£Œ: ì´ 2306ê°œ íŒŒì¼ ì €ì¥ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ¨ ì›ë³¸ RGB â†’ í´ë˜ìŠ¤ ID ë§¤í•‘\n",
    "rgb_to_class = {\n",
    "    (208, 88, 255): 1, (88, 38, 128): 3, (230, 170, 255): 1, (138, 60, 200): 1,\n",
    "    (255, 128, 255): 1, (255, 155, 155): 3, (128, 96, 0): 3, (255, 255, 0): 3,\n",
    "    (255, 128, 0): 3, (255, 0, 0): 0, (105, 105, 255): 3, (255, 192, 0): 0,\n",
    "    (0, 255, 0): 0, (255, 0, 255): 1, (128, 128, 128): 2, (0, 0, 255): 2,\n",
    "    (217, 217, 217): 2, (55, 86, 35): 3, (110, 168, 70): 2, (255, 230, 153): 2,\n",
    "    (198, 89, 17): 2, (0, 0, 0): 3\n",
    "}\n",
    "\n",
    "# í´ë˜ìŠ¤ â†’ ìƒ‰ìƒ (ì»¬ëŸ¬ìš©)\n",
    "color_map = {\n",
    "    0: (255, 0, 0),      # ë¹¨ê°•\n",
    "    1: (255, 255, 0),    # ë…¸ë‘\n",
    "    2: (0, 255, 0),      # ì´ˆë¡\n",
    "    3: (0, 0, 0)         # ê²€ì • (background)\n",
    "}\n",
    "\n",
    "# í´ë˜ìŠ¤ â†’ ë°ê¸° (í‘ë°±ìš©)\n",
    "brightness_map = {\n",
    "    0: 200,  # caution zone (ì£¼ì˜ êµ¬ê°„)\n",
    "    1: 150,  # roadway + alley\n",
    "    2: 100,  # sidewalk (ì¸ë„)\n",
    "    3: 50    # background (ë°°ê²½)\n",
    "}\n",
    "\n",
    "# ğŸ” ì†Œë¬¸ì íŒŒì¼ë§Œ íŒë³„\n",
    "def is_lower_filename(filename):\n",
    "    name_only = os.path.splitext(os.path.basename(filename))[0]\n",
    "    letters = [c for c in name_only if c.isalpha()]\n",
    "    return letters and all(c.islower() for c in letters)\n",
    "\n",
    "# RGB â†’ í´ë˜ìŠ¤ ë§µí•‘\n",
    "def rgb_to_class_map(image_np):\n",
    "    h, w, _ = image_np.shape\n",
    "    class_map = np.full((h, w), 3, dtype=np.uint8)  # ê¸°ë³¸ê°’ background\n",
    "\n",
    "    for rgb, class_id in rgb_to_class.items():\n",
    "        mask = np.all(image_np == np.array(rgb), axis=-1)\n",
    "        class_map[mask] = class_id\n",
    "\n",
    "    return class_map\n",
    "\n",
    "# í´ë˜ìŠ¤ â†’ RGB ì»¬ëŸ¬ ë§µí•‘\n",
    "def class_to_rgb(mask_2d):\n",
    "    h, w = mask_2d.shape\n",
    "    rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    for class_id, color in color_map.items():\n",
    "        mask = (mask_2d == class_id)\n",
    "        rgb[..., 0][mask] = color[0]\n",
    "        rgb[..., 1][mask] = color[1]\n",
    "        rgb[..., 2][mask] = color[2]\n",
    "\n",
    "    return rgb\n",
    "\n",
    "# í´ë˜ìŠ¤ â†’ í‘ë°± ë§µí•‘ (ë°ê¸° ê°’)\n",
    "def class_to_gray(mask_2d):\n",
    "    gray = np.zeros(mask_2d.shape, dtype=np.uint8)\n",
    "\n",
    "    for class_id, brightness in brightness_map.items():\n",
    "        mask = (mask_2d == class_id)\n",
    "        gray[mask] = brightness\n",
    "\n",
    "    return gray\n",
    "\n",
    "# ë©”ì¸ ë³€í™˜ í•¨ìˆ˜ (ğŸ”¥ ì „ì²´ ì´ë¯¸ì§€ ë³€í™˜)\n",
    "def process_images(input_dir, output_color_dir, output_gray_dir):\n",
    "    print(f\"\\nğŸš€ ë³€í™˜ ì‹œì‘: {input_dir}\")\n",
    "\n",
    "    image_paths = glob.glob(os.path.join(input_dir, \"*.png\"))\n",
    "    total_images = len(image_paths)\n",
    "    print(f\"ì´ {total_images}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # ğŸ”¤ ì†Œë¬¸ì íŒŒì¼ë§Œ ì„ íƒ\n",
    "    lower_files = [f for f in image_paths if is_lower_filename(f)]\n",
    "    print(f\"ğŸ”¤ ì†Œë¬¸ì ì´ë¯¸ì§€: {len(lower_files)}ê°œ\")\n",
    "\n",
    "    # ì €ì¥ í´ë” ìƒì„±\n",
    "    os.makedirs(output_color_dir, exist_ok=True)\n",
    "    os.makedirs(output_gray_dir, exist_ok=True)\n",
    "\n",
    "    for in_path in tqdm(lower_files, desc=\"ğŸ¨ ì»¬ëŸ¬ + í‘ë°± ë³€í™˜ ì¤‘\"):\n",
    "        image = Image.open(in_path).convert(\"RGB\")\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        class_map = rgb_to_class_map(image_np)\n",
    "\n",
    "        # ğŸ¨ ì»¬ëŸ¬ ì €ì¥\n",
    "        rgb_label = class_to_rgb(class_map)\n",
    "        out_color_path = os.path.join(output_color_dir, os.path.basename(in_path))\n",
    "        Image.fromarray(rgb_label).save(out_color_path)\n",
    "\n",
    "        # ğŸ–¤ í‘ë°± ì €ì¥ (íŒŒì¼ëª…ì€ ëŒ€ë¬¸ì)\n",
    "        gray_label = class_to_gray(class_map)\n",
    "        base_name = os.path.splitext(os.path.basename(in_path))[0]\n",
    "        upper_name = base_name.upper() + \".png\"\n",
    "        out_gray_path = os.path.join(output_gray_dir, upper_name)\n",
    "        Image.fromarray(gray_label).save(out_gray_path)\n",
    "\n",
    "    print(f\"\\nâœ… ë³€í™˜ ì™„ë£Œ: ì´ {len(lower_files)}ê°œ íŒŒì¼ ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "# ğŸ”¥ ì‚¬ìš© ì˜ˆì‹œ\n",
    "input_dir = \"/home/segmentsafestep/Fast-SCNN-pytorch-master/datasets/indobohaeng/gtFine_5class/Val/alley\"\n",
    "output_color_dir = \"/home/segmentsafestep/Fast-SCNN-pytorch-master/datasets/indobohaeng/gtFine/Val/alley\"\n",
    "output_gray_dir = \"/home/segmentsafestep/Fast-SCNN-pytorch-master/datasets/indobohaeng/gtFine/Val/alley\"\n",
    "\n",
    "process_images(input_dir, output_color_dir, output_gray_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201487ca-adac-4890-a660-a77c09d4e80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ë³€í™˜ ì‹œì‘: /home/segmentsafestep/Fast-SCNN-pytorch-master/datasets/indobohaeng/gtFine_5class/Train/alley\n",
      "ì´ 18451ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ğŸ”¤ ì†Œë¬¸ì ì´ë¯¸ì§€: 18451ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ¨ ì»¬ëŸ¬ + í‘ë°± ë³€í™˜ ì¤‘:   0%|                                                   | 3/18451 [00:05<9:06:58,  1.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18720/4263017401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0moutput_gray_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/segmentsafestep/Fast-SCNN-pytorch-master/datasets/indobohaeng/gtFine/Train/alley\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_color_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_gray_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_18720/4263017401.py\u001b[0m in \u001b[0;36mprocess_images\u001b[0;34m(input_dir, output_color_dir, output_gray_dir)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mimage_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mclass_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb_to_class_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# ğŸ¨ ì»¬ëŸ¬ ì €ì¥\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18720/4263017401.py\u001b[0m in \u001b[0;36mrgb_to_class_map\u001b[0;34m(image_np)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrgb_to_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_np\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mclass_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ğŸ¨ ì›ë³¸ RGB â†’ í´ë˜ìŠ¤ ID ë§¤í•‘\n",
    "rgb_to_class = {\n",
    "    (208, 88, 255): 1, (88, 38, 128): 3, (230, 170, 255): 1, (138, 60, 200): 1,\n",
    "    (255, 128, 255): 1, (255, 155, 155): 3, (128, 96, 0): 3, (255, 255, 0): 3,\n",
    "    (255, 128, 0): 3, (255, 0, 0): 0, (105, 105, 255): 3, (255, 192, 0): 0,\n",
    "    (0, 255, 0): 0, (255, 0, 255): 1, (128, 128, 128): 2, (0, 0, 255): 2,\n",
    "    (217, 217, 217): 2, (55, 86, 35): 3, (110, 168, 70): 2, (255, 230, 153): 2,\n",
    "    (198, 89, 17): 2, (0, 0, 0): 3\n",
    "}\n",
    "\n",
    "# í´ë˜ìŠ¤ â†’ ìƒ‰ìƒ (ì»¬ëŸ¬ìš©)\n",
    "color_map = {\n",
    "    0: (255, 0, 0),      # ë¹¨ê°•\n",
    "    1: (255, 255, 0),    # ë…¸ë‘\n",
    "    2: (0, 255, 0),      # ì´ˆë¡\n",
    "    3: (0, 0, 0)         # ê²€ì • (background)\n",
    "}\n",
    "\n",
    "# í´ë˜ìŠ¤ â†’ ë°ê¸° (í‘ë°±ìš©)\n",
    "brightness_map = {\n",
    "    0: 200,  # caution zone (ì£¼ì˜ êµ¬ê°„)\n",
    "    1: 150,  # roadway + alley\n",
    "    2: 100,  # sidewalk (ì¸ë„)\n",
    "    3: 50    # background (ë°°ê²½)\n",
    "}\n",
    "\n",
    "# ğŸ” ì†Œë¬¸ì íŒŒì¼ë§Œ íŒë³„\n",
    "def is_lower_filename(filename):\n",
    "    name_only = os.path.splitext(os.path.basename(filename))[0]\n",
    "    letters = [c for c in name_only if c.isalpha()]\n",
    "    return letters and all(c.islower() for c in letters)\n",
    "\n",
    "# RGB â†’ í´ë˜ìŠ¤ ë§µí•‘\n",
    "def rgb_to_class_map(image_np):\n",
    "    h, w, _ = image_np.shape\n",
    "    class_map = np.full((h, w), 3, dtype=np.uint8)  # ê¸°ë³¸ê°’ background\n",
    "\n",
    "    for rgb, class_id in rgb_to_class.items():\n",
    "        mask = np.all(image_np == np.array(rgb), axis=-1)\n",
    "        class_map[mask] = class_id\n",
    "\n",
    "    return class_map\n",
    "\n",
    "# í´ë˜ìŠ¤ â†’ RGB ì»¬ëŸ¬ ë§µí•‘\n",
    "def class_to_rgb(mask_2d):\n",
    "    h, w = mask_2d.shape\n",
    "    rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    for class_id, color in color_map.items():\n",
    "        mask = (mask_2d == class_id)\n",
    "        rgb[..., 0][mask] = color[0]\n",
    "        rgb[..., 1][mask] = color[1]\n",
    "        rgb[..., 2][mask] = color[2]\n",
    "\n",
    "    return rgb\n",
    "\n",
    "# í´ë˜ìŠ¤ â†’ í‘ë°± ë§µí•‘ (ë°ê¸° ê°’)\n",
    "def class_to_gray(mask_2d):\n",
    "    gray = np.zeros(mask_2d.shape, dtype=np.uint8)\n",
    "\n",
    "    for class_id, brightness in brightness_map.items():\n",
    "        mask = (mask_2d == class_id)\n",
    "        gray[mask] = brightness\n",
    "\n",
    "    return gray\n",
    "\n",
    "# ë©”ì¸ ë³€í™˜ í•¨ìˆ˜ (ğŸ”¥ ì „ì²´ ì´ë¯¸ì§€ ë³€í™˜)\n",
    "def process_images(input_dir, output_color_dir, output_gray_dir):\n",
    "    print(f\"\\nğŸš€ ë³€í™˜ ì‹œì‘: {input_dir}\")\n",
    "\n",
    "    image_paths = glob.glob(os.path.join(input_dir, \"*.png\"))\n",
    "    total_images = len(image_paths)\n",
    "    print(f\"ì´ {total_images}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # ğŸ”¤ ì†Œë¬¸ì íŒŒì¼ë§Œ ì„ íƒ\n",
    "    lower_files = [f for f in image_paths if is_lower_filename(f)]\n",
    "    print(f\"ğŸ”¤ ì†Œë¬¸ì ì´ë¯¸ì§€: {len(lower_files)}ê°œ\")\n",
    "\n",
    "    # ì €ì¥ í´ë” ìƒì„±\n",
    "    os.makedirs(output_color_dir, exist_ok=True)\n",
    "    os.makedirs(output_gray_dir, exist_ok=True)\n",
    "\n",
    "    for in_path in tqdm(lower_files, desc=\"ğŸ¨ ì»¬ëŸ¬ + í‘ë°± ë³€í™˜ ì¤‘\"):\n",
    "        image = Image.open(in_path).convert(\"RGB\")\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        class_map = rgb_to_class_map(image_np)\n",
    "\n",
    "        # ğŸ¨ ì»¬ëŸ¬ ì €ì¥\n",
    "        rgb_label = class_to_rgb(class_map)\n",
    "        out_color_path = os.path.join(output_color_dir, os.path.basename(in_path))\n",
    "        Image.fromarray(rgb_label).save(out_color_path)\n",
    "\n",
    "        # ğŸ–¤ í‘ë°± ì €ì¥ (íŒŒì¼ëª…ì€ ëŒ€ë¬¸ì)\n",
    "        gray_label = class_to_gray(class_map)\n",
    "        base_name = os.path.splitext(os.path.basename(in_path))[0]\n",
    "        upper_name = base_name.upper() + \".png\"\n",
    "        out_gray_path = os.path.join(output_gray_dir, upper_name)\n",
    "        Image.fromarray(gray_label).save(out_gray_path)\n",
    "\n",
    "    print(f\"\\nâœ… ë³€í™˜ ì™„ë£Œ: ì´ {len(lower_files)}ê°œ íŒŒì¼ ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "# ğŸ”¥ ì‚¬ìš© ì˜ˆì‹œ\n",
    "input_dir = \"/home/segmentsafestep/Fast-SCNN-pytorch-master/datasets/indobohaeng/gtFine_5class/Train/alley\"\n",
    "output_color_dir = \"/home/segmentsafestep/Fast-SCNN-pytorch-master/datasets/indobohaeng/gtFine/Train/alley\"\n",
    "output_gray_dir = \"/home/segmentsafestep/Fast-SCNN-pytorch-master/datasets/indobohaeng/gtFine/Train/alley\"\n",
    "\n",
    "process_images(input_dir, output_color_dir, output_gray_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b61ce6-972f-48b8-b839-067f4cb70f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
