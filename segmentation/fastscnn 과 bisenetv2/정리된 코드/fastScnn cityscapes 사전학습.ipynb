{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d5ebff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['.ipynb_checkpoints', 'bisenetv2.py', '__pycache__', 'modules.py', '__init__.py', 'model_registry.py', 'BiSeNet_V2.py', 'fastscnn.py', 'fast_scnn.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 'models' 폴더가 있는지 확인\n",
    "models_path = \"/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/models\"\n",
    "print(os.path.exists(models_path))  # True면 존재, False면 없음\n",
    "\n",
    "# 폴더 내부 파일 확인\n",
    "if os.path.exists(models_path):\n",
    "    print(os.listdir(models_path))  # 'fast_scnn.py'가 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d746202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 경로 목록:\n",
      "/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master\n",
      "/aiffel/storage/package\n",
      "/opt/conda/lib/python39.zip\n",
      "/opt/conda/lib/python3.9\n",
      "/opt/conda/lib/python3.9/lib-dynload\n",
      "\n",
      "/opt/conda/lib/python3.9/site-packages\n",
      "/opt/conda/lib/python3.9/site-packages/IPython/extensions\n",
      "/aiffel/.ipython\n",
      "/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/models\n",
      "/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/utils\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Python 모듈 경로에 'models' 폴더 추가\n",
    "models_path = \"/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/models\"\n",
    "utils_path = \"/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/utils\"\n",
    "\n",
    "if models_path not in sys.path:\n",
    "    sys.path.append(models_path)  # models 폴더 추가\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)  # utils 폴더 추가\n",
    "\n",
    "# sys.path 확인 (제대로 추가되었는지)\n",
    "print(\"Python 경로 목록:\")\n",
    "print(\"\\n\".join(sys.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774aec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "# PyTorch 관련 라이브러리\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# 이미지 변환 관련 라이브러리\n",
    "from torchvision import transforms\n",
    "\n",
    "# 데이터 로더 및 모델, 유틸리티 함수 불러오기\n",
    "from data_loader import get_segmentation_dataset  # 데이터셋 불러오는 함수\n",
    "from models.fast_scnn import get_fast_scnn  # Fast-SCNN 모델 불러오기\n",
    "from utils.loss import MixSoftmaxCrossEntropyLoss, MixSoftmaxCrossEntropyOHEMLoss  # 손실 함수\n",
    "from utils.lr_scheduler import LRScheduler  # 학습률 스케줄러\n",
    "from utils.metric import SegmentationMetric  # 평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b59c9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 및 학습 관련 하이퍼파라미터 설정\n",
    "args = {\n",
    "    \"model\": \"fast_scnn\",  # 사용할 모델 이름\n",
    "    \"dataset\": \"citys\",  # 학습할 데이터셋 (예: Cityscapes)\n",
    "    \"base_size\": 1024,  # 입력 이미지 기본 크기\n",
    "    \"crop_size\": 768,  # 학습 시 사용할 크롭 크기\n",
    "    \"train_split\": \"train\",  # 학습 데이터셋의 분할 방식\n",
    "\n",
    "    # 학습 하이퍼파라미터\n",
    "    \"aux\": False,  # 보조 손실 사용 여부\n",
    "    \"aux_weight\": 0.4,  # 보조 손실 가중치\n",
    "    \"epochs\": 10,  # 학습 에폭 수\n",
    "    \"start_epoch\": 0,  # 학습 시작 에폭\n",
    "    \"batch_size\": 2,  # 배치 크기\n",
    "    \"lr\": 1e-2,  # 학습률\n",
    "    \"momentum\": 0.9,  # 모멘텀\n",
    "    \"weight_decay\": 1e-4,  # 가중치 감쇠 (L2 정규화)\n",
    "\n",
    "    # 체크포인트 저장 위치\n",
    "    \"resume\": True,  # 기존 모델 체크포인트 (사용하지 않음)\n",
    "    \"save_folder\": \"./weights\",  # 모델 가중치 저장 경로\n",
    "\n",
    "    # 평가 및 검증 설정\n",
    "    \"eval\": True,  # 평가 모드 여부\n",
    "    \"no_val\": False,  # 검증 생략 여부\n",
    "}\n",
    "\n",
    "# GPU 사용 여부 설정\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True  # GPU 연산 최적화\n",
    "args[\"device\"] = device  # 학습에 사용할 디바이스 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f53ec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 'train' 폴더 존재 여부: True\n",
      "📂 'train' 폴더 내부 파일: ['zurich', 'monchengladbach', 'strasbourg', 'weimar', 'erfurt', 'stuttgart', 'tubingen', 'ulm', 'cologne', 'krefeld', 'hamburg', 'aachen', 'jena', 'bremen', 'bochum', 'dusseldorf', 'darmstadt', 'hanover']\n"
     ]
    }
   ],
   "source": [
    "train_img_path = \"/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/datasets/citys/leftImg8bit/train\"\n",
    "\n",
    "# train 폴더 존재 여부 확인\n",
    "print(\"📂 'train' 폴더 존재 여부:\", os.path.exists(train_img_path))\n",
    "\n",
    "# train 폴더 내부 파일 확인\n",
    "if os.path.exists(train_img_path):\n",
    "    print(\"📂 'train' 폴더 내부 파일:\", os.listdir(train_img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc2dae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Found gtFine folder at: /aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/datasets/citys/gtFine\n"
     ]
    }
   ],
   "source": [
    "dataset_root = \"/aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/datasets\"\n",
    "\n",
    "# 🔍 `gtFine` 폴더가 어디 있는지 확인\n",
    "for root, dirs, files in os.walk(dataset_root):\n",
    "    if \"gtFine\" in dirs:\n",
    "        print(f\"📂 Found gtFine folder at: {os.path.join(root, 'gtFine')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "188a67bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2975 images in /aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/datasets/citys/leftImg8bit/train\n",
      "Found 500 images in /aiffel/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/datasets/citys/leftImg8bit/val\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FastSCNN(\n",
       "  (learning_to_downsample): LearningToDownsample(\n",
       "    (conv): _ConvBNReLU(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dsconv1): _DSConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dsconv2): _DSConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (global_feature_extractor): GlobalFeatureExtractor(\n",
       "    (bottleneck1): Sequential(\n",
       "      (0): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bottleneck2): Sequential(\n",
       "      (0): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bottleneck3): Sequential(\n",
       "      (0): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): LinearBottleneck(\n",
       "        (block): Sequential(\n",
       "          (0): _ConvBNReLU(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _DWConv(\n",
       "            (conv): Sequential(\n",
       "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ppm): PyramidPooling(\n",
       "      (conv1): _ConvBNReLU(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2): _ConvBNReLU(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv3): _ConvBNReLU(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv4): _ConvBNReLU(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (out): _ConvBNReLU(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feature_fusion): FeatureFusionModule(\n",
       "    (dwconv): _DWConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_lower_res): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_higher_res): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Classifer(\n",
       "    (dsconv1): _DSConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (dsconv2): _DSConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv): Sequential(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 전처리 변환 설정\n",
    "input_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 이미지를 Tensor로 변환\n",
    "    transforms.Normalize([.485, .456, .406], [.229, .224, .225]),  # 이미지 정규화\n",
    "])\n",
    "\n",
    "# 데이터셋 로드 (학습 및 검증)\n",
    "data_kwargs = {\"transform\": input_transform, \"base_size\": args[\"base_size\"], \"crop_size\": args[\"crop_size\"]}\n",
    "train_dataset = get_segmentation_dataset(args[\"dataset\"], split=args[\"train_split\"], mode=\"train\", **data_kwargs)\n",
    "val_dataset = get_segmentation_dataset(args[\"dataset\"], split=\"val\", mode=\"val\", **data_kwargs)\n",
    "\n",
    "# DataLoader 생성 (데이터 배치 단위로 로딩)\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=args[\"batch_size\"], shuffle=True, drop_last=True)\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Fast-SCNN 모델 생성\n",
    "model = get_fast_scnn(dataset=args[\"dataset\"], aux=args[\"aux\"])\n",
    "\n",
    "# GPU 병렬 처리 지원 (멀티 GPU 사용 가능)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0, 1, 2])\n",
    "\n",
    "# 모델을 GPU 또는 CPU로 이동\n",
    "model.to(args[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8379a3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastSCNN(\n",
      "  (learning_to_downsample): LearningToDownsample(\n",
      "    (conv): _ConvBNReLU(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (dsconv1): _DSConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (dsconv2): _DSConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (global_feature_extractor): GlobalFeatureExtractor(\n",
      "    (bottleneck1): Sequential(\n",
      "      (0): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bottleneck2): Sequential(\n",
      "      (0): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bottleneck3): Sequential(\n",
      "      (0): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): LinearBottleneck(\n",
      "        (block): Sequential(\n",
      "          (0): _ConvBNReLU(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _DWConv(\n",
      "            (conv): Sequential(\n",
      "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ppm): PyramidPooling(\n",
      "      (conv1): _ConvBNReLU(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv2): _ConvBNReLU(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv3): _ConvBNReLU(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv4): _ConvBNReLU(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (out): _ConvBNReLU(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feature_fusion): FeatureFusionModule(\n",
      "    (dwconv): _DWConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv_lower_res): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv_higher_res): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Classifer(\n",
      "    (dsconv1): _DSConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (dsconv2): _DSConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv): Sequential(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)  # 모델이 정상적으로 선언되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4d68ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ class balance\n"
     ]
    }
   ],
   "source": [
    "# 손실 함수 설정 (OHEM Loss 사용)\n",
    "criterion = MixSoftmaxCrossEntropyOHEMLoss(aux=args[\"aux\"], aux_weight=args[\"aux_weight\"], ignore_index=-1).to(args[\"device\"])\n",
    "\n",
    "# 옵티마이저 (SGD 사용)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=args[\"lr\"], momentum=args[\"momentum\"], weight_decay=args[\"weight_decay\"])\n",
    "\n",
    "# 학습률 스케줄러 설정 (poly decay 사용)\n",
    "lr_scheduler = LRScheduler(mode=\"poly\", base_lr=args[\"lr\"], nepochs=args[\"epochs\"],\n",
    "                           iters_per_epoch=len(train_loader), power=0.9)\n",
    "\n",
    "# 평가 지표 (mIoU 등)\n",
    "metric = SegmentationMetric(train_dataset.num_class)\n",
    "\n",
    "# 최고 성능 저장을 위한 변수\n",
    "best_pred = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c4e5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global best_pred  # 최고 성능 비교를 위한 전역 변수 사용\n",
    "    cur_iters = 0  # 현재 반복 횟수\n",
    "    start_time = time.time()  # 학습 시작 시간\n",
    "\n",
    "    # 각 에폭마다 학습 수행\n",
    "    for epoch in range(args[\"start_epoch\"], args[\"epochs\"]):\n",
    "        model.train()  # 모델을 학습 모드로 설정\n",
    "\n",
    "        for i, (images, targets) in enumerate(train_loader):\n",
    "            cur_lr = lr_scheduler(cur_iters)  # 현재 학습률 설정\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = cur_lr  # 옵티마이저에 학습률 적용\n",
    "\n",
    "            # 데이터를 GPU/CPU로 이동\n",
    "            images, targets = images.to(args[\"device\"]), targets.to(args[\"device\"])\n",
    "\n",
    "            # 모델 예측 및 손실 계산\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # 역전파 및 최적화 수행\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            cur_iters += 1  # 반복 횟수 증가\n",
    "            if cur_iters % 10 == 0:  # 10회마다 로그 출력\n",
    "                print(f\"Epoch [{epoch}/{args['epochs']}], Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # 검증 수행 및 체크포인트 저장\n",
    "        if not args[\"no_val\"]:\n",
    "            validation(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ef92eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    global best_pred  # 최고 성능 비교를 위한 전역 변수 사용\n",
    "    model.eval()  # 모델을 평가 모드로 변경\n",
    "    metric.reset()  # 평가 지표 초기화\n",
    "\n",
    "    for i, (image, target) in enumerate(val_loader):\n",
    "        image = image.to(args[\"device\"])  # 이미지를 GPU/CPU로 이동\n",
    "\n",
    "        with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "            outputs = model(image)\n",
    "\n",
    "        pred = torch.argmax(outputs[0], 1).cpu().data.numpy()  # 예측 결과 가져오기\n",
    "        metric.update(pred, target.numpy())  # 평가 지표 업데이트\n",
    "\n",
    "    pixAcc, mIoU = metric.get()  # 픽셀 정확도 및 mIoU 계산\n",
    "    print(f\"Epoch {epoch}, Validation PixAcc: {pixAcc:.3f}, mIoU: {mIoU:.3f}\")\n",
    "\n",
    "    new_pred = (pixAcc + mIoU) / 2  # 성능 평가\n",
    "    if new_pred > best_pred:\n",
    "        best_pred = new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d4a1e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10], Step [9/1487], Loss: 1.6984\n",
      "Epoch [0/10], Step [19/1487], Loss: 2.1239\n",
      "Epoch [0/10], Step [29/1487], Loss: 2.0295\n",
      "Epoch [0/10], Step [39/1487], Loss: 2.1423\n",
      "Epoch [0/10], Step [49/1487], Loss: 1.4570\n",
      "Epoch [0/10], Step [59/1487], Loss: 1.7141\n",
      "Epoch [0/10], Step [69/1487], Loss: 1.4954\n",
      "Epoch [0/10], Step [79/1487], Loss: 1.5687\n",
      "Epoch [0/10], Step [89/1487], Loss: 2.0716\n",
      "Epoch [0/10], Step [99/1487], Loss: 1.7081\n",
      "Epoch [0/10], Step [109/1487], Loss: 2.5222\n",
      "Epoch [0/10], Step [119/1487], Loss: 1.4102\n",
      "Epoch [0/10], Step [129/1487], Loss: 1.8364\n",
      "Epoch [0/10], Step [139/1487], Loss: 1.6245\n",
      "Epoch [0/10], Step [149/1487], Loss: 2.1214\n",
      "Epoch [0/10], Step [159/1487], Loss: 1.2951\n",
      "Epoch [0/10], Step [169/1487], Loss: 1.9539\n",
      "Epoch [0/10], Step [179/1487], Loss: 1.6137\n",
      "Epoch [0/10], Step [189/1487], Loss: 1.8407\n",
      "Epoch [0/10], Step [199/1487], Loss: 2.1681\n",
      "Epoch [0/10], Step [209/1487], Loss: 1.5661\n",
      "Epoch [0/10], Step [219/1487], Loss: 1.3354\n",
      "Epoch [0/10], Step [229/1487], Loss: 1.0910\n",
      "Epoch [0/10], Step [239/1487], Loss: 1.8617\n",
      "Epoch [0/10], Step [249/1487], Loss: 1.7552\n",
      "Epoch [0/10], Step [259/1487], Loss: 1.3287\n",
      "Epoch [0/10], Step [269/1487], Loss: 0.8835\n",
      "Epoch [0/10], Step [279/1487], Loss: 2.0748\n",
      "Epoch [0/10], Step [289/1487], Loss: 1.8686\n",
      "Epoch [0/10], Step [299/1487], Loss: 1.7459\n",
      "Epoch [0/10], Step [309/1487], Loss: 2.0701\n",
      "Epoch [0/10], Step [319/1487], Loss: 2.0815\n",
      "Epoch [0/10], Step [329/1487], Loss: 1.6378\n",
      "Epoch [0/10], Step [339/1487], Loss: 1.0346\n",
      "Epoch [0/10], Step [349/1487], Loss: 2.1617\n",
      "Epoch [0/10], Step [359/1487], Loss: 1.5996\n",
      "Epoch [0/10], Step [369/1487], Loss: 1.3395\n",
      "Epoch [0/10], Step [379/1487], Loss: 1.3044\n",
      "Epoch [0/10], Step [389/1487], Loss: 1.9684\n",
      "Epoch [0/10], Step [399/1487], Loss: 1.8221\n",
      "Epoch [0/10], Step [409/1487], Loss: 1.2148\n",
      "Epoch [0/10], Step [419/1487], Loss: 2.2878\n",
      "Epoch [0/10], Step [429/1487], Loss: 1.0897\n",
      "Epoch [0/10], Step [439/1487], Loss: 1.8783\n",
      "Epoch [0/10], Step [449/1487], Loss: 2.1254\n",
      "Epoch [0/10], Step [459/1487], Loss: 1.9082\n",
      "Epoch [0/10], Step [469/1487], Loss: 1.5183\n",
      "Epoch [0/10], Step [479/1487], Loss: 1.1856\n",
      "Epoch [0/10], Step [489/1487], Loss: 1.1039\n",
      "Epoch [0/10], Step [499/1487], Loss: 1.3850\n",
      "Epoch [0/10], Step [509/1487], Loss: 1.7692\n",
      "Epoch [0/10], Step [519/1487], Loss: 1.1901\n",
      "Epoch [0/10], Step [529/1487], Loss: 1.2255\n",
      "Epoch [0/10], Step [539/1487], Loss: 1.7085\n",
      "Epoch [0/10], Step [549/1487], Loss: 1.4465\n",
      "Epoch [0/10], Step [559/1487], Loss: 1.5739\n",
      "Epoch [0/10], Step [569/1487], Loss: 1.4968\n",
      "Epoch [0/10], Step [579/1487], Loss: 1.1759\n",
      "Epoch [0/10], Step [589/1487], Loss: 1.9207\n",
      "Epoch [0/10], Step [599/1487], Loss: 1.4850\n",
      "Epoch [0/10], Step [609/1487], Loss: 1.5424\n",
      "Epoch [0/10], Step [619/1487], Loss: 2.3259\n",
      "Epoch [0/10], Step [629/1487], Loss: 0.9589\n",
      "Epoch [0/10], Step [639/1487], Loss: 2.7854\n",
      "Epoch [0/10], Step [649/1487], Loss: 1.2647\n",
      "Epoch [0/10], Step [659/1487], Loss: 2.0985\n",
      "Epoch [0/10], Step [669/1487], Loss: 2.8104\n",
      "Epoch [0/10], Step [679/1487], Loss: 1.3176\n",
      "Epoch [0/10], Step [689/1487], Loss: 1.0936\n",
      "Epoch [0/10], Step [699/1487], Loss: 1.9969\n",
      "Epoch [0/10], Step [709/1487], Loss: 2.5464\n",
      "Epoch [0/10], Step [719/1487], Loss: 1.5387\n",
      "Epoch [0/10], Step [729/1487], Loss: 1.9397\n",
      "Epoch [0/10], Step [739/1487], Loss: 1.0302\n",
      "Epoch [0/10], Step [749/1487], Loss: 1.5023\n",
      "Epoch [0/10], Step [759/1487], Loss: 1.5055\n",
      "Epoch [0/10], Step [769/1487], Loss: 1.1510\n",
      "Epoch [0/10], Step [779/1487], Loss: 1.5884\n",
      "Epoch [0/10], Step [789/1487], Loss: 1.5008\n",
      "Epoch [0/10], Step [799/1487], Loss: 2.4832\n",
      "Epoch [0/10], Step [809/1487], Loss: 1.0713\n",
      "Epoch [0/10], Step [819/1487], Loss: 1.0631\n",
      "Epoch [0/10], Step [829/1487], Loss: 2.2233\n",
      "Epoch [0/10], Step [839/1487], Loss: 1.0809\n",
      "Epoch [0/10], Step [849/1487], Loss: 1.2609\n",
      "Epoch [0/10], Step [859/1487], Loss: 2.6322\n",
      "Epoch [0/10], Step [869/1487], Loss: 1.8297\n",
      "Epoch [0/10], Step [879/1487], Loss: 1.4062\n",
      "Epoch [0/10], Step [889/1487], Loss: 1.3260\n",
      "Epoch [0/10], Step [899/1487], Loss: 1.6917\n",
      "Epoch [0/10], Step [909/1487], Loss: 1.4675\n",
      "Epoch [0/10], Step [919/1487], Loss: 2.1544\n",
      "Epoch [0/10], Step [929/1487], Loss: 1.0185\n",
      "Epoch [0/10], Step [939/1487], Loss: 1.2007\n",
      "Epoch [0/10], Step [949/1487], Loss: 2.0397\n",
      "Epoch [0/10], Step [959/1487], Loss: 1.0580\n",
      "Epoch [0/10], Step [969/1487], Loss: 1.2528\n",
      "Epoch [0/10], Step [979/1487], Loss: 1.3412\n",
      "Epoch [0/10], Step [989/1487], Loss: 1.9848\n",
      "Epoch [0/10], Step [999/1487], Loss: 1.5030\n",
      "Epoch [0/10], Step [1009/1487], Loss: 4.4350\n",
      "Epoch [0/10], Step [1019/1487], Loss: 1.3963\n",
      "Epoch [0/10], Step [1029/1487], Loss: 1.1061\n",
      "Epoch [0/10], Step [1039/1487], Loss: 1.5683\n",
      "Epoch [0/10], Step [1049/1487], Loss: 1.7266\n",
      "Epoch [0/10], Step [1059/1487], Loss: 1.3342\n",
      "Epoch [0/10], Step [1069/1487], Loss: 1.6502\n",
      "Epoch [0/10], Step [1079/1487], Loss: 1.4327\n",
      "Epoch [0/10], Step [1089/1487], Loss: 1.7473\n",
      "Epoch [0/10], Step [1099/1487], Loss: 1.5208\n",
      "Epoch [0/10], Step [1109/1487], Loss: 1.3866\n",
      "Epoch [0/10], Step [1119/1487], Loss: 1.0815\n",
      "Epoch [0/10], Step [1129/1487], Loss: 1.2476\n",
      "Epoch [0/10], Step [1139/1487], Loss: 1.7420\n",
      "Epoch [0/10], Step [1149/1487], Loss: 1.3661\n",
      "Epoch [0/10], Step [1159/1487], Loss: 1.2156\n",
      "Epoch [0/10], Step [1169/1487], Loss: 1.3085\n",
      "Epoch [0/10], Step [1179/1487], Loss: 1.0748\n",
      "Epoch [0/10], Step [1189/1487], Loss: 1.4073\n",
      "Epoch [0/10], Step [1199/1487], Loss: 1.2499\n",
      "Epoch [0/10], Step [1209/1487], Loss: 1.2046\n",
      "Epoch [0/10], Step [1219/1487], Loss: 2.0282\n",
      "Epoch [0/10], Step [1229/1487], Loss: 1.8089\n",
      "Epoch [0/10], Step [1239/1487], Loss: 1.1074\n",
      "Epoch [0/10], Step [1249/1487], Loss: 1.2026\n",
      "Epoch [0/10], Step [1259/1487], Loss: 1.4315\n",
      "Epoch [0/10], Step [1269/1487], Loss: 1.5152\n",
      "Epoch [0/10], Step [1279/1487], Loss: 1.2723\n",
      "Epoch [0/10], Step [1289/1487], Loss: 1.3169\n",
      "Epoch [0/10], Step [1299/1487], Loss: 1.4018\n",
      "Epoch [0/10], Step [1309/1487], Loss: 1.0477\n",
      "Epoch [0/10], Step [1319/1487], Loss: 2.2070\n",
      "Epoch [0/10], Step [1329/1487], Loss: 1.4879\n",
      "Epoch [0/10], Step [1339/1487], Loss: 0.9701\n",
      "Epoch [0/10], Step [1349/1487], Loss: 1.6721\n",
      "Epoch [0/10], Step [1359/1487], Loss: 1.2448\n",
      "Epoch [0/10], Step [1369/1487], Loss: 1.4519\n",
      "Epoch [0/10], Step [1379/1487], Loss: 1.0859\n",
      "Epoch [0/10], Step [1389/1487], Loss: 1.4396\n",
      "Epoch [0/10], Step [1399/1487], Loss: 3.3655\n",
      "Epoch [0/10], Step [1409/1487], Loss: 2.6691\n",
      "Epoch [0/10], Step [1419/1487], Loss: 1.5767\n",
      "Epoch [0/10], Step [1429/1487], Loss: 1.3931\n",
      "Epoch [0/10], Step [1439/1487], Loss: 1.7842\n",
      "Epoch [0/10], Step [1449/1487], Loss: 1.2066\n",
      "Epoch [0/10], Step [1459/1487], Loss: 1.2053\n",
      "Epoch [0/10], Step [1469/1487], Loss: 1.4126\n",
      "Epoch [0/10], Step [1479/1487], Loss: 1.0258\n",
      "Epoch 0, Validation PixAcc: 0.817, mIoU: 0.197\n",
      "Epoch [1/10], Step [2/1487], Loss: 1.5527\n",
      "Epoch [1/10], Step [12/1487], Loss: 0.8897\n",
      "Epoch [1/10], Step [22/1487], Loss: 2.0318\n",
      "Epoch [1/10], Step [32/1487], Loss: 1.0497\n",
      "Epoch [1/10], Step [42/1487], Loss: 1.7643\n",
      "Epoch [1/10], Step [52/1487], Loss: 1.7934\n",
      "Epoch [1/10], Step [62/1487], Loss: 1.0345\n",
      "Epoch [1/10], Step [72/1487], Loss: 1.5978\n",
      "Epoch [1/10], Step [82/1487], Loss: 1.2543\n",
      "Epoch [1/10], Step [92/1487], Loss: 1.7044\n",
      "Epoch [1/10], Step [102/1487], Loss: 1.6678\n",
      "Epoch [1/10], Step [112/1487], Loss: 2.1271\n",
      "Epoch [1/10], Step [122/1487], Loss: 1.7572\n",
      "Epoch [1/10], Step [132/1487], Loss: 1.0134\n",
      "Epoch [1/10], Step [142/1487], Loss: 1.1593\n",
      "Epoch [1/10], Step [152/1487], Loss: 1.3203\n",
      "Epoch [1/10], Step [162/1487], Loss: 1.0061\n",
      "Epoch [1/10], Step [172/1487], Loss: 1.2956\n",
      "Epoch [1/10], Step [182/1487], Loss: 2.2166\n",
      "Epoch [1/10], Step [192/1487], Loss: 0.8275\n",
      "Epoch [1/10], Step [202/1487], Loss: 1.1134\n",
      "Epoch [1/10], Step [212/1487], Loss: 1.4325\n",
      "Epoch [1/10], Step [222/1487], Loss: 1.6833\n",
      "Epoch [1/10], Step [232/1487], Loss: 1.1990\n",
      "Epoch [1/10], Step [242/1487], Loss: 1.3488\n",
      "Epoch [1/10], Step [252/1487], Loss: 1.2242\n",
      "Epoch [1/10], Step [262/1487], Loss: 2.1031\n",
      "Epoch [1/10], Step [272/1487], Loss: 1.7372\n",
      "Epoch [1/10], Step [282/1487], Loss: 1.1702\n",
      "Epoch [1/10], Step [292/1487], Loss: 2.0115\n",
      "Epoch [1/10], Step [302/1487], Loss: 1.0719\n",
      "Epoch [1/10], Step [312/1487], Loss: 1.0588\n",
      "Epoch [1/10], Step [322/1487], Loss: 1.2002\n",
      "Epoch [1/10], Step [332/1487], Loss: 2.4756\n",
      "Epoch [1/10], Step [342/1487], Loss: 0.9701\n",
      "Epoch [1/10], Step [352/1487], Loss: 2.0005\n",
      "Epoch [1/10], Step [362/1487], Loss: 2.1460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [372/1487], Loss: 1.8904\n",
      "Epoch [1/10], Step [382/1487], Loss: 1.4418\n",
      "Epoch [1/10], Step [392/1487], Loss: 1.1142\n",
      "Epoch [1/10], Step [402/1487], Loss: 1.1185\n",
      "Epoch [1/10], Step [412/1487], Loss: 1.4657\n",
      "Epoch [1/10], Step [422/1487], Loss: 1.0007\n",
      "Epoch [1/10], Step [432/1487], Loss: 1.7595\n",
      "Epoch [1/10], Step [442/1487], Loss: 1.4036\n",
      "Epoch [1/10], Step [452/1487], Loss: 1.0686\n",
      "Epoch [1/10], Step [462/1487], Loss: 1.3525\n",
      "Epoch [1/10], Step [472/1487], Loss: 1.3537\n",
      "Epoch [1/10], Step [482/1487], Loss: 1.0825\n",
      "Epoch [1/10], Step [492/1487], Loss: 1.4741\n",
      "Epoch [1/10], Step [502/1487], Loss: 1.6350\n",
      "Epoch [1/10], Step [512/1487], Loss: 1.7159\n",
      "Epoch [1/10], Step [522/1487], Loss: 1.5469\n",
      "Epoch [1/10], Step [532/1487], Loss: 1.0567\n",
      "Epoch [1/10], Step [542/1487], Loss: 1.5321\n",
      "Epoch [1/10], Step [552/1487], Loss: 1.1166\n",
      "Epoch [1/10], Step [562/1487], Loss: 3.7772\n",
      "Epoch [1/10], Step [572/1487], Loss: 1.4862\n",
      "Epoch [1/10], Step [582/1487], Loss: 1.6080\n",
      "Epoch [1/10], Step [592/1487], Loss: 1.3586\n",
      "Epoch [1/10], Step [602/1487], Loss: 1.5337\n",
      "Epoch [1/10], Step [612/1487], Loss: 1.5995\n",
      "Epoch [1/10], Step [622/1487], Loss: 1.2151\n",
      "Epoch [1/10], Step [632/1487], Loss: 1.9095\n",
      "Epoch [1/10], Step [642/1487], Loss: 1.9407\n",
      "Epoch [1/10], Step [652/1487], Loss: 1.0465\n",
      "Epoch [1/10], Step [662/1487], Loss: 1.5238\n",
      "Epoch [1/10], Step [672/1487], Loss: 1.3173\n",
      "Epoch [1/10], Step [682/1487], Loss: 2.3505\n",
      "Epoch [1/10], Step [692/1487], Loss: 0.9730\n",
      "Epoch [1/10], Step [702/1487], Loss: 0.8187\n",
      "Epoch [1/10], Step [712/1487], Loss: 1.4580\n",
      "Epoch [1/10], Step [722/1487], Loss: 1.2289\n",
      "Epoch [1/10], Step [732/1487], Loss: 1.4908\n",
      "Epoch [1/10], Step [742/1487], Loss: 5.0667\n",
      "Epoch [1/10], Step [752/1487], Loss: 1.2834\n",
      "Epoch [1/10], Step [762/1487], Loss: 1.1705\n",
      "Epoch [1/10], Step [772/1487], Loss: 1.6588\n",
      "Epoch [1/10], Step [782/1487], Loss: 1.6832\n",
      "Epoch [1/10], Step [792/1487], Loss: 1.6049\n",
      "Epoch [1/10], Step [802/1487], Loss: 2.1417\n",
      "Epoch [1/10], Step [812/1487], Loss: 1.1839\n",
      "Epoch [1/10], Step [822/1487], Loss: 1.0866\n",
      "Epoch [1/10], Step [832/1487], Loss: 1.2285\n",
      "Epoch [1/10], Step [842/1487], Loss: 1.9098\n",
      "Epoch [1/10], Step [852/1487], Loss: 1.2743\n",
      "Epoch [1/10], Step [862/1487], Loss: 1.5863\n",
      "Epoch [1/10], Step [872/1487], Loss: 1.6600\n",
      "Epoch [1/10], Step [882/1487], Loss: 1.0863\n",
      "Epoch [1/10], Step [892/1487], Loss: 3.9118\n",
      "Epoch [1/10], Step [902/1487], Loss: 1.9892\n",
      "Epoch [1/10], Step [912/1487], Loss: 1.2061\n",
      "Epoch [1/10], Step [922/1487], Loss: 1.1396\n",
      "Epoch [1/10], Step [932/1487], Loss: 2.1957\n",
      "Epoch [1/10], Step [942/1487], Loss: 1.4038\n",
      "Epoch [1/10], Step [952/1487], Loss: 1.4847\n",
      "Epoch [1/10], Step [962/1487], Loss: 1.3469\n",
      "Epoch [1/10], Step [972/1487], Loss: 1.4811\n",
      "Epoch [1/10], Step [982/1487], Loss: 1.2400\n",
      "Epoch [1/10], Step [992/1487], Loss: 1.5225\n",
      "Epoch [1/10], Step [1002/1487], Loss: 1.1559\n",
      "Epoch [1/10], Step [1012/1487], Loss: 1.3687\n",
      "Epoch [1/10], Step [1022/1487], Loss: 1.0919\n",
      "Epoch [1/10], Step [1032/1487], Loss: 1.1929\n",
      "Epoch [1/10], Step [1042/1487], Loss: 0.9303\n",
      "Epoch [1/10], Step [1052/1487], Loss: 1.5033\n",
      "Epoch [1/10], Step [1062/1487], Loss: 2.8932\n",
      "Epoch [1/10], Step [1072/1487], Loss: 1.7936\n",
      "Epoch [1/10], Step [1082/1487], Loss: 1.3767\n",
      "Epoch [1/10], Step [1092/1487], Loss: 1.1362\n",
      "Epoch [1/10], Step [1102/1487], Loss: 2.0278\n",
      "Epoch [1/10], Step [1112/1487], Loss: 1.2497\n",
      "Epoch [1/10], Step [1122/1487], Loss: 1.9330\n",
      "Epoch [1/10], Step [1132/1487], Loss: 1.0721\n",
      "Epoch [1/10], Step [1142/1487], Loss: 1.1959\n",
      "Epoch [1/10], Step [1152/1487], Loss: 1.4769\n",
      "Epoch [1/10], Step [1162/1487], Loss: 1.6629\n",
      "Epoch [1/10], Step [1172/1487], Loss: 1.3840\n",
      "Epoch [1/10], Step [1182/1487], Loss: 0.9324\n",
      "Epoch [1/10], Step [1192/1487], Loss: 1.1198\n",
      "Epoch [1/10], Step [1202/1487], Loss: 1.5438\n",
      "Epoch [1/10], Step [1212/1487], Loss: 1.9913\n",
      "Epoch [1/10], Step [1222/1487], Loss: 1.1239\n",
      "Epoch [1/10], Step [1232/1487], Loss: 1.1197\n",
      "Epoch [1/10], Step [1242/1487], Loss: 1.8706\n",
      "Epoch [1/10], Step [1252/1487], Loss: 0.9547\n",
      "Epoch [1/10], Step [1262/1487], Loss: 1.1446\n",
      "Epoch [1/10], Step [1272/1487], Loss: 1.0588\n",
      "Epoch [1/10], Step [1282/1487], Loss: 1.1384\n",
      "Epoch [1/10], Step [1292/1487], Loss: 1.5051\n",
      "Epoch [1/10], Step [1302/1487], Loss: 1.4434\n",
      "Epoch [1/10], Step [1312/1487], Loss: 1.4146\n",
      "Epoch [1/10], Step [1322/1487], Loss: 1.1435\n",
      "Epoch [1/10], Step [1332/1487], Loss: 1.7276\n",
      "Epoch [1/10], Step [1342/1487], Loss: 1.9016\n",
      "Epoch [1/10], Step [1352/1487], Loss: 1.2302\n",
      "Epoch [1/10], Step [1362/1487], Loss: 3.4463\n",
      "Epoch [1/10], Step [1372/1487], Loss: 1.5998\n",
      "Epoch [1/10], Step [1382/1487], Loss: 2.5807\n",
      "Epoch [1/10], Step [1392/1487], Loss: 0.9958\n",
      "Epoch [1/10], Step [1402/1487], Loss: 1.5799\n",
      "Epoch [1/10], Step [1412/1487], Loss: 1.3317\n",
      "Epoch [1/10], Step [1422/1487], Loss: 1.1983\n",
      "Epoch [1/10], Step [1432/1487], Loss: 1.3108\n",
      "Epoch [1/10], Step [1442/1487], Loss: 2.3813\n",
      "Epoch [1/10], Step [1452/1487], Loss: 1.2907\n",
      "Epoch [1/10], Step [1462/1487], Loss: 1.1928\n",
      "Epoch [1/10], Step [1472/1487], Loss: 0.8134\n",
      "Epoch [1/10], Step [1482/1487], Loss: 1.1354\n",
      "Epoch 1, Validation PixAcc: 0.837, mIoU: 0.220\n",
      "Epoch [2/10], Step [5/1487], Loss: 1.7048\n",
      "Epoch [2/10], Step [15/1487], Loss: 1.8692\n",
      "Epoch [2/10], Step [25/1487], Loss: 1.6231\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_599/4055063839.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 학습 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_599/3182864978.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# 모델 예측 및 손실 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# 역전파 및 최적화 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/utils/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aux_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMixSoftmaxCrossEntropyOHEMLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/aiffel/aiffel project model training/Fast-SCNN-pytorch-master/utils/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, predict, target, weight)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_kept\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0mthreshold_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_kept\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthreshold_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()  # 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986b56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
